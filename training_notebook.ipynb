{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8faf791",
   "metadata": {},
   "source": [
    "# Ice Cream Sales â€” Training Notebook\n",
    "\n",
    "This notebook trains two classifiers (Decision Tree and SVM) on the provided `Ice_Cream.csv` dataset.\n",
    "It creates a binary label `HighRevenue` (Revenue >= median), fits models, evaluates them, and saves artifacts into a `models/` folder.\n",
    "Running the notebook will also write a deployable `app.py` Streamlit file into the project root."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b0bf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "print('pandas', pd.__version__)\n",
    "print('numpy', np.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9962d8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "# Use __file__ when available (interactive run), otherwise fall back to current working directory (nbconvert)\n",
    "try:\n",
    "    base_dir = os.path.dirname(__file__)\n",
    "except NameError:\n",
    "    base_dir = os.getcwd()\n",
    "csv_path = os.path.join(base_dir, 'Ice_Cream.csv')\n",
    "df = pd.read_csv(csv_path)\n",
    "print('Loaded dataset with shape:', df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4845084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary label using the median revenue\n",
    "median_revenue = df['Revenue'].median()\n",
    "df['HighRevenue'] = (df['Revenue'] >= median_revenue).astype(int)\n",
    "print('Median revenue threshold:', median_revenue)\n",
    "print(df['HighRevenue'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0701c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and labels\n",
    "X = df[['Temperature']].values\n",
    "y = df['HighRevenue'].values\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print('Train shape:', X_train.shape, 'Test shape:', X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b7ce34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Decision Tree\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "dt_acc = accuracy_score(y_test, y_pred_dt)\n",
    "print('Decision Tree accuracy:', dt_acc)\n",
    "print('\n",
    "Decision Tree classification report:\n",
    "', classification_report(y_test, y_pred_dt))\n",
    "\n",
    "# Train SVM with scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)\n",
    "svm = SVC(kernel='rbf', probability=True, random_state=42)\n",
    "svm.fit(X_train_s, y_train)\n",
    "y_pred_svm = svm.predict(X_test_s)\n",
    "svm_acc = accuracy_score(y_test, y_pred_svm)\n",
    "print('SVM accuracy:', svm_acc)\n",
    "print('\n",
    "SVM classification report:\n",
    "', classification_report(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bea9690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save models and artifacts\n",
    "out_dir = os.path.join(os.path.dirname(__file__), 'models')\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "joblib.dump(dt, os.path.join(out_dir, 'decision_tree.joblib'))\n",
    "joblib.dump(svm, os.path.join(out_dir, 'svm_model.joblib'))\n",
    "joblib.dump(scaler, os.path.join(out_dir, 'scaler.joblib'))\n",
    "results = {\n",
    "    'decision_tree': {'accuracy': dt_acc, 'confusion_matrix': confusion_matrix(y_test, y_pred_dt).tolist()},\n",
    "    'svm': {'accuracy': svm_acc, 'confusion_matrix': confusion_matrix(y_test, y_pred_svm).tolist()}\n",
    "}\n",
    "joblib.dump(results, os.path.join(out_dir, 'results.joblib'))\n",
    "print('Saved artifacts to', out_dir)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
